# -*- coding: utf-8 -*-
"""Lung Cancer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_xYzk9vMeRqARlVJnU0uwaB-_l4ihiPF
"""

#Our project targets on developing a machine learning classification model for diagnosing Lancaster using a lung cancer dataset
#. The aim for this project is to predict if the patient have cancer or not based on the features .
#To accomplish this we used multiple machine learning algorithms,including SVM , logistic regression, random forest .
#Through experiencing with these models and evaluating ,
# our goal is to find the most effective approach for long cancer detection potentially assisting healthcare professionals in making more accurate diagnosis

# Commented out IPython magic to ensure Python compatibility.
#in this code we imported the importing libraries for data visualization,tools for training and splitting,
#evaluation ,statical analysis,
#as well as sitting up environment for plots


import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np

from scipy import stats
from scipy.stats import norm, skew

from sklearn.model_selection import train_test_split # 4.1
from sklearn.linear_model import LogisticRegression  # 4.2
from sklearn.ensemble import RandomForestClassifier  # 4.3
from sklearn.svm import SVC                          # 4.5
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score

# %config InlineBackend.figure_format = 'retina'

# Model Accuracies
ml_accuracies = dict()

#Here we loaded CSV file into data frame
#Also cleaning the column names by converting them into lowercase and replacing the spaces with Underscore


df = pd.read_csv("/content/cancer patient data sets.csv", index_col='index')

# Index Column now refers to patient
df.drop("Patient Id", axis=1, inplace=True)

# cleaning column names
df.rename(columns=str.lower, inplace=True)
df.rename(columns={col: col.replace(" ", "_") for col in df.columns}, inplace=True)

display(df)

#this command helps in understanding the structure of the dataset which will display the information of the data frame including columns names data types
#and also the number of none- nullvalues to each column
print(df.info())

#In this code will show us the statistics of the data frame that will enhance the reability and understanding  the statistics of the  dataset

print('Cancer Levels: ', df['level'].unique())

# Replacing levels of numeric int
mapping = {'High': 2, 'Medium': 1, 'Low': 0}
df["level"].replace(mapping, inplace=True)
print('Cancer Levels: ', df['level'].unique())

#This code we replaced categorical levels of cancer with numeric values , because machine learning models typically require numeric inputs
round(df.describe().iloc[1:, ].T, 3).style.format(precision=3).background_gradient(axis=1)

#In this code the dataset is split into X for features and y for the target label by dropping “level” column which is the target in our data set ,
# then the first five values of the target variable will be printed
X = df.drop(columns='level')
y = df.level

display(X.head())
print(y[:5])

#Visualizing the Data Distribution (Pie Chart):
#We want to understand the distribution of the target variable level in the dataset. A pie chart is a simple way to visualize the proportion of each class
#it shows how many samples there are for each level of cancer (Low, Medium, High),This helps to understand the balance of classes .

plt.figure(figsize=(6, 6))
plt.title('Training Data', fontsize=20)
plt.pie(df.level.value_counts(),
    labels=mapping.keys(),
    colors=['#FAC500','#0BFA00', '#0066FA','#FA0000'],
    autopct=lambda p: '{:.2f}%\n{:,.0f}'.format(p, p * sum(df.level.value_counts() /100)),
    explode=tuple(0.01 for i in range(3)),
    textprops={'fontsize': 20}
)
plt.show()

# Correlation plot
#Correlation Heatmap :A correlation heatmap helps identify relationships between the features in the dataset ,it reveals which features are strongly correlated with each other,
# helping us decide whether to drop highly correlated features (to avoid multicollinearity) or retain them for model training.
plt.figure(figsize=(20,15))
sns.heatmap(df.corr(), annot=True, cmap=plt.cm.PuBu)
plt.show()

#Splitting the Data into Training and Testing Sets :We split the data into training and testing sets to evaluate the performance of our models on unseen data
#,30% of the data will be used for testing, while 70% will be used for training.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=40)
print(f'Shapes - X Training: {X_train.shape} and X Testing {X_test.shape}')
print(f'Shapes - Y Training: {y_train.shape} and Y Testing {y_test.shape}')

print(f'\nTraining output counts\n{y_train.value_counts()}')

!pip install seaborn scikit-learn

#SVM Model Training and Evaluation : we used A hyperparameter that controls the regularization strength, A smaller value of C allows more margin violations
 #(which can help when there's noise in the data). the SVM tries to find the best hyperplane that maximally separates the different classes while minimizing errors.
svm_model = SVC(C=0.5, kernel='linear')
svm_model.fit(X_train, y_train)

svm_pred = svm_model.predict(X_test)

# Import necessary libraries
import seaborn as sns  # For data visualization
import matplotlib.pyplot as plt  # For plotting
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report  # For model evaluation

# Define a function to plot the confusion matrix
def CM(y_true, y_pred, col_names, title, cmap='Blues'):
    # Compute the confusion matrix
    cm = confusion_matrix(y_true, y_pred)

    # Set the size of the plot
    plt.figure(figsize=(8, 6))

    # Plot the confusion matrix as a heatmap
    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap,
                xticklabels=col_names, yticklabels=col_names)

    # Set plot title and labels
    plt.title(f'Confusion Matrix {title}')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')

    # Show the plot
    plt.show()

# Call the CM function to plot confusion matrix for SVM model predictions
CM(y_test, svm_pred, col_names=['Low', 'Medium', 'High'], title='- SVM', cmap='Reds')

# Calculate and store accuracy for SVM model
ml_accuracies['SVM'] = accuracy_score(y_test, svm_pred)

# Print classification report for SVM model
print(classification_report(y_test, svm_pred))

from sklearn.linear_model import LogisticRegression

# Assuming 'x_test' and 'X_train', 'y_train' are defined in a previous cell
# Assigning the LogisticRegression model to the variable 'model_lr'
model_lr = LogisticRegression()
model_lr.fit(X_train, y_train)

# Now, 'model_lr' is defined and can be used for prediction
pred = model_lr.predict(X_test)

#Calculate accuracy score for model predictions
score = accuracy_score(pred, y_test)

#Print the accuracy score
print(score)

#Compute confusion matrix
cm = confusion_matrix(pred, y_test)
cm
#This will give you the confusion matrix, where:
#cm[0,0] is the count of true negatives,
#cm[1,1] is the count of true positives,
#cm[0,1] is the count of false positives, and
#cm[1,0] is the count of false negatives.

#The expression df['level'] accesses the column named level in the DataFrame df. This command will return a Seriescontaining the data in that column.
# View the data in the level column:
df['level']

# Import necessary libraries for model training, evaluation, and splitting data
from sklearn.model_selection import train_test_split  # For splitting data into training and test sets
from sklearn.metrics import accuracy_score, confusion_matrix  # For calculating accuracy and confusion matrix
from sklearn.metrics import log_loss, f1_score  # For calculating log loss and F1 score
from sklearn.model_selection import cross_val_score  # For cross-validation

import numpy as np  # For numerical operations

# Initialize an empty dictionary to store accuracy scores
acc_dict = {}

# Prepare the data for training and testing
X = df.drop('level', axis=1)  # Drop the target variable from features
y = df['level']  # Target variable

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y)

from sklearn.ensemble import  RandomForestClassifier
# create model
model = RandomForestClassifier()

# fit the data in the model
model.fit(X_train,y_train)

# Get predicted probabilities instead of class labels
y_pred_proba = model.predict_proba(X_test)

# Use predicted probabilities for log loss calculation
acc_dict['RFC_log_loss'] = log_loss(y_test, y_pred_proba)

y_pred_randomF = model.predict(X_test)
print('Accuracy score : ',accuracy_score(y_test, y_pred_randomF)*100)

acc_dict['RFC_F1_Score'] = f1_score(y_test, y_pred_randomF,average='weighted')

# prediction visualization
plt.imshow(np.log(confusion_matrix(y_test,y_pred_randomF)),cmap = 'Greens',interpolation = 'nearest')
plt.ylabel('True')
plt.xlabel('Predicted')
plt.show()